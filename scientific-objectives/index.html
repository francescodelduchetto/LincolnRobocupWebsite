<!doctype html><html class="h-full bg-gray-100 font-serif"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon type=image/x-icon href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//favicon.ico><link rel=stylesheet type=text/css href=https://francescodelduchetto.github.io/LincolnRobocupWebsite/css/index.babba0580f44e2d5f9d21bac147cb448.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;700&display=swap" rel=stylesheet><title>LCASTOR website</title></head><body class=h-full><div class=min-h-full><nav class=bg-gray-800><div class="px-3 sm:px-3.5 lg:px-8"><div class="flex h-20 items-center justify-between"><div class="text-white font-bold text-lg flex items-center"><img class=mr-3 src=https://francescodelduchetto.github.io/LincolnRobocupWebsite//LCASTOR_image.png alt="LCASTOR Team Logo" width=80 height=80><div class="px-3 md:px-0">LCASTOR Team Homepage</div></div><div class="text-white flex space-x-1.5 hidden lg:block text-sm"><div class="inline px-3 py-2 rounded-md hover:bg-gray-700"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//>Home</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//members>Team Members</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//scientific-objectives>Scientific Objectives</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//competitions>Competitions</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//robots>Our Robots</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//software>Software</a></p></div></div></div><div class="flex flex-col space-y-1.5 text-sm pb-4 text-white block lg:hidden"><div class="inline px-3 py-2 rounded-md hover:bg-gray-700 w-fit"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//>Home</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700 w-fit"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//members>Team Members</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700 w-fit"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//scientific-objectives>Scientific Objectives</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700 w-fit"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//competitions>Competitions</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700 w-fit"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//robots>Our Robots</a></p></div><div class="inline px-3 py-2 rounded-md hover:bg-gray-700 w-fit"><p class=inline><a href=https://francescodelduchetto.github.io/LincolnRobocupWebsite//software>Software</a></p></div></div></div></nav><div id=content class="grid justify-items-center"><div class="w-11/12 pt-6 md:w-10/12 md:pt-8 lg:w-8/12 xl:w-7/12"><h1 id=scientific-objectives>Scientific Objectives</h1><p>We present the main scientific contributions achieved by the research group and the research topics relevant to the RoboCup@Home competitions and outline how they will contribute and be further developed in this context.</p><h2 id=planning-and-plan-execution>Planning and plan execution</h2><p>The deployment of robots in populated environments interacting with non-expert users requires facing many sources of uncertainty during task execution such as incomplete information about the environment or unpredictable behaviours coming from humans. Planning and plan execution under such uncertainties is also an important problem to be addressed within the RoboCup@Home competition and, in this context, we have recent research results.</p><p>In <strong>[Polvara-RAL21]</strong>, we propose Next-Best-Sense (NBS), a decision-making framework that allows a mobile robot to explore an environment looking for objects while combining multiple criteria in a single utility function. Modelled following the traditional sense-plan-act paradigm, NBS iteratively select a new robot pose in order to efficiently explore an environment while carrying out a survey task. We further extend NBS in <strong>[Polvara-RAL22]</strong>, where we propose a topological formulation of a particle filter for tracking multiple fruit harvesters in a polytunnel scenario, by integrating 2D LiDARs, RFID, and GPS readings.</p><h2 id=human-robot-interaction>Human-Robot Interaction</h2><p>When social robots are deployed in public environments their ability of initiating and sustaining interactions with users is of vital importance. In a previous long-term deployment of an autonomous robot in a public museum, <strong>[DelDuchetto-ROMAN19]</strong> it is reported how the engagement of users quickly decreases over time for long and non-interactive tasks. Therefore, with the goal of obtainig a better sense of the users state during interactions, in <strong>[DelDuchetto-FROBAI]</strong> a regression model is trained to assess users&rsquo; engagement in real-time from the robot point of view.</p><p>To maintain engaging interactions with its users, robots need to adapt in real-time to different changing users state and behaviour. In this direction <strong>[DelDuchetto-RAL22]</strong> proposes an adaptation framework where a robot deployed in long-term scenarios learns from first-hand experience during interactions what is the best action to perform at each moment during an interaction based on the engagement state of the users. This method has proven to increase the time users spend interacting with the robot.</p><h2 id=navigation-and-localisation>Navigation and Localisation</h2><p>Human inhabitated environments like homes, museums and shopping malls are challenging scenarios to navigate in for mobile robots.</p><p>In this context, <strong>[Krajnik-IROS16]</strong> presented a localization and mapping system based on a spatiotemporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future. The proposed representation improves the localisation accuracy and the efficiency of path planning. In <strong>[Fentanes-ICRA15]</strong>, we present an approach for the topological navigation of service robots in dynamic indoor environments this approach uses a topological representation of the environment that simplifies the definition of navigation actions and is augmented with a spatiotemporal model that specifically represents changes that stem from events in the environment, which impact on the success probability of planned actions which allows the robot to predict action outcomes and to devise better navigation plans. In <strong>[Hanheide-HRI17]</strong>, we have also shown how better HRI can be facilitated by exploiting long-term spatiotemporal experience, similar to the approach above, but directly linking long-term autonomy with setting goals for a mobile robot. In populated environments, the ability to be able to predict the directions people are heading is useful for robots to plan suitable paths. The machine learning method in <strong>[Sun-ICRA18]</strong> allows us to learn a model for such predictions from long-term experience.
In <strong>[DelDuchetto-RAL18]</strong> a method is proposed to learn to detect and recover from navigation failures using the help that the robot receives from nearby humans. The proposed approach enables the robot to automatically generate recovery trajectories in future failures, improving the autonomy of the robot navigation in long-term scenarios.</p><h2 id=robot-vision>Robot Vision</h2><h3 id=references>References</h3><ul><li><strong>[DelDuchetto-RAL18]</strong> F. Del Duchetto, A. Kucukyilmaz, L. Iocchi and M. Hanheide, <strong>&ldquo;Do Not Make the Same Mistakes Again and Again: Learning Local Recovery Policies for Navigation From Human Demonstrations&rdquo;</strong>, in IEEE Robotics and Automation Letters, vol. 3, no. 4, pp. 4084-4091, Oct. 2018, doi: <a href=https://doi.org/10.1109/LRA.2018.2861080>10.1109/LRA.2018.2861080</a>.</li><li><strong>[DelDuchetto-ROMAN19]</strong> F. Del Duchetto, P. Baxter and M. Hanheide, <strong>&ldquo;Lindsey the Tour Guide Robot - Usage Patterns in a Museum Long-Term Deployment&rdquo;</strong>, 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), New Delhi, India, 2019, pp. 1-8, doi: <a href=https://doi.org/10.1109/RO-MAN46459.2019.8956329>10.1109/RO-MAN46459.2019.8956329</a>.</li><li><strong>[DelDuchetto-FROBAI20]</strong> Del Duchetto F, Baxter P and Hanheide M (2020) <strong>&ldquo;Are You Still With Me? Continuous Engagement Assessment From a Robot&rsquo;s Point of View&rdquo;</strong>, Frontiers in Robotics and AI 7:116. doi: <a href=https://doi.org/10.3389/frobt.2020.00116>10.3389/frobt.2020.00116</a></li><li><strong>[DelDuchetto-RAL22]</strong> F. Del Duchetto and M. Hanheide, <strong>&ldquo;Learning on the Job: Long-Term Behavioural Adaptation in Human-Robot Interactions&rdquo;</strong>, in IEEE Robotics and Automation Letters, vol. 7, no. 3, pp. 6934-6941, July 2022, doi: <a href=https://doi.org/10.1109/LRA.2022.3178807>10.1109/LRA.2022.3178807</a>.</li><li><strong>[Fentanes-ICRA15]</strong> J. P. Fentanes, B. Lacerda, T. Krajn√≠k, N. Hawes and M. Hanheide, <strong>&ldquo;Now or later? Predicting and maximising success of navigation actions from long-term experience&rdquo;</strong>, in 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, WA, USA, 2015, pp. 1112-1117, doi: <a href=https://doi.org/10.1109/ICRA.2015.7139315>10.1109/ICRA.2015.7139315</a>.</li><li><strong>[Krajnik-IROS16]</strong> T. Krajn√≠k, J. Pulido Fentanes, M. Hanheide and T. Duckett, <strong>&ldquo;Persistent localization and life-long mapping in changing environments using the Frequency Map Enhancement&rdquo;</strong>, 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, Korea (South), 2016, pp. 4558-4563, doi: <a href=https://doi.org/10.1109/IROS.2016.7759671>10.1109/IROS.2016.7759671</a>.</li><li><strong>[Hanheide-HRI17]</strong> M. Hanheide, D. Hebesberger and T. Krajn√≠k, <strong>&ldquo;The when, where, and how: An adaptive robotic info-terminal for care home residents&rdquo;</strong>, in Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction, pp. 341-349, March 2017, doi: <a href=https://doi.org/10.1145/2909824.3020228>10.1145/2909824.3020228</a></li><li><strong>[Polvara-RAL21]</strong> R. Polvara, M. Fernandez-Carmona, G. Neumann and M. Hanheide, <strong>&ldquo;Next-Best-Sense: A Multi-Criteria Robotic Exploration Strategy for RFID Tags Discovery&rdquo;</strong>, in IEEE Robotics and Automation Letters, vol. 5, no. 3, pp. 4477-4484, July 2020, doi: <a href=https://doi.org/10.1109/LRA.2020.3001539>10.1109/LRA.2020.3001539</a>.</li><li><strong>[Polvara-RAL22]</strong> R. Polvara, F. Del Duchetto, G. Neumann and M. Hanheide, <strong>&ldquo;Navigate-and-Seek: A Robotics Framework for People Localization in Agricultural Environments&rdquo;</strong>, in IEEE Robotics and Automation Letters, vol. 6, no. 4, pp. 6577-6584, Oct. 2021, doi: <a href=https://doi.org/10.1109/LRA.2021.3094557>10.1109/LRA.2021.3094557</a>.</li><li><strong>[Sun-ICRA18]</strong> L. Sun, Z. Yan, S. M. Mellado, M. Hanheide and T. Duckett, <strong>&ldquo;3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data&rdquo;</strong>, in 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 2018, pp. 5942-5948, doi: <a href=https://doi.org/10.1109/ICRA.2018.8461228>10.1109/ICRA.2018.8461228</a>.</li></ul></div></div></div></body></html>